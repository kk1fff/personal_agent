# Personal Agent System Configuration
# Copy this file to config.yaml and fill in your credentials

telegram:
  bot_token: "YOUR_BOT_TOKEN"
  mode: "poll"  # or "webhook"
  webhook_url: ""  # required if mode is webhook
  require_mention: false  # Set to true to enable @mention filtering
  # bot_username: "YourBotName"  # Optional - auto-detected if not provided

allowed_conversations:
  - chat_id: 123456789
  - chat_id: -987654321  # group chat (negative ID)

allowed_users:
  - user_id: 123456789

llm:
  provider: "ollama"  # or "openai" or "gemini"
  
  # Ollama configuration (for local LLM)
  ollama:
    base_url: "http://localhost:11434"
    model: "llama2"
    temperature: 0.7
    max_tokens: 2048
    context_window: 4096
  
  # OpenAI configuration (for ChatGPT)
  openai:
    api_key: "YOUR_OPENAI_API_KEY"
    model: "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 2048
    organization_id: ""  # optional
  
  # Gemini configuration (for Google Gemini)
  gemini:
    api_key: "YOUR_GEMINI_API_KEY"
    model: "gemini-pro"
    temperature: 0.7
    max_tokens: 2048
    safety_settings: null  # optional

tools:
  notion:
    api_key: "YOUR_NOTION_API_KEY"

    # Workspaces to index (for notion-indexer CLI)
    workspaces:
      - name: "personal"
        # Root page IDs to start indexing from
        root_page_ids:
          - "abc123..."  # Replace with your root page ID
        # Optional: Database IDs to index
        database_ids: []
        # Optional: Page IDs to exclude from indexing
        exclude_page_ids: []
        # Maximum depth to traverse in page hierarchy
        max_depth: 10

    # ChromaDB collection name for Notion index
    index_collection: "notion_pages"

    # Delay between Notion API calls (seconds) to avoid rate limits
    rate_limit_delay: 0.35

    # Default number of search results
    search_results_default: 5

  google_calendar:
    # Option 1: Use credentials file
    credentials_path: "path/to/credentials.json"
    # Option 2: Use service account
    service_account_email: ""
    service_account_key: ""

database:
  conversation_db: "data/conversations.db"
  vector_db_path: "data/vector_db"

# Agent Configuration and Preferences
agent:
  # Agent preferences (global settings)
  preferences:
    # Timezone for datetime formatting in prompts
    # Use IANA timezone names (e.g., 'America/New_York', 'Europe/London', 'Asia/Tokyo')
    # Find valid timezones at: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
    # Common timezones:
    #   - "UTC" - Coordinated Universal Time
    #   - "America/New_York" - Eastern Time (US)
    #   - "America/Los_Angeles" - Pacific Time (US)
    #   - "Europe/London" - British Time
    #   - "Asia/Tokyo" - Japan Standard Time
    #   - "Australia/Sydney" - Australian Eastern Time
    timezone: "UTC"

    # Preferred response language (ISO 639-1 language code)
    # Common codes: en (English), zh (Chinese), es (Spanish), fr (French), de (German), ja (Japanese), ko (Korean)
    language: "en"

  # Whether to inject current datetime into agent prompts
  # Set to false if you want static prompts without time awareness
  inject_datetime: true

  # Context retrieval configuration
  context:
    # Maximum number of previous messages agent can request via tool (Deprecated for tool usage, used as default backup)
    max_history: 5

    # Time gap threshold for session detection (minutes) (Deprecated for tool usage)
    # Messages separated by more than this are considered different sessions
    # Used when agent requests "smart" context mode
    time_gap_threshold_minutes: 60

    # Maximum messages to inspect when performing time-gap clustering
    lookback_limit: 25

    # Maximum recent references to pull for LLM summarization
    message_limit: 20

  # Multi-agent Orchestrator Configuration
  # When enabled, uses a Dispatcher (Concierge) to route requests to Specialist agents
  orchestrator:
    # Enable multi-agent orchestrator pattern
    # When false (default), uses legacy single-agent mode
    enable: true

    # Optional: Override LLM model for dispatcher
    # If not set, uses the main LLM configuration
    # dispatcher_model: "gpt-4"

    # Optional: Override LLM models per specialist
    # specialist_models:
    #   notion_specialist: "gpt-4"
    #   calendar_specialist: "gpt-3.5-turbo"

  # Debug and Logging Configuration
  debug:
    # Create separate log file for each Telegram response
    # Useful for debugging agent behavior
    enable_response_logging: false

    # Generate SVG data flow diagrams for each response
    # Shows how requests flow through the multi-agent system
    enable_svg_diagrams: false

    # Directory for per-response log files
    response_log_dir: "data/response_logs/responses"

    # Directory for SVG diagram files
    svg_diagram_dir: "data/response_logs/diagrams"